{"cells":[{"cell_type":"markdown","metadata":{"id":"QzfhDJ8X8nmn"},"source":["# Lab: NBA Players Analyse"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PkQFISiB8nmr"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","# 1.Data process and time series plot\n","\n","1.Load the data\n","\n","games_details.csv includes details of games dataset, all statistics of players for a given game\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1878,"status":"ok","timestamp":1699404063506,"user":{"displayName":"Haoyang Ling","userId":"12767123704845142451"},"user_tz":300},"id":"sil2sQv7-Y0J","outputId":"229fb7cf-4afb-4d16-e6f4-540648c84956"},"outputs":[],"source":["df=pd.read_csv('games_details.csv',header=0,low_memory=False)\n","print(df)"]},{"cell_type":"markdown","metadata":{},"source":["2.Preprocess the data\n","\n","fill none with \"00:00\" in the column MIN\n","\n","fill none with 0 in the column FGM to the last column\n","\n","modify the MIN column to make sure the time is correct"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Vb8Bpli-fQb"},"outputs":[],"source":["df[df.columns[10:]].fillna(0,inplace=True)\n","df['MIN'].fillna('00:00',inplace=True)\n","def deal_time(x):\n","    split_string=x.split(':')\n","    return float(split_string[0])\n","df['MIN']=df['MIN'].apply(lambda x:deal_time(x))\n","print(df['MIN'])\n"]},{"cell_type":"markdown","metadata":{},"source":["3.Extract the star players data \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["group=['LeBron James','Kevin Durant']\n","dic_group={}\n","for name in group:\n","    dic_group[name]=df[df['PLAYER_NAME'].isin([name])].copy()\n","    dic_group[name].reset_index(inplace=True)\n","print(dic_group.keys())\n"]},{"cell_type":"markdown","metadata":{},"source":["4.Get the game date for every player from  games.csv according to the game id"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_games=pd.read_csv('games.csv',header=0,low_memory=False)\n","print(df_games)\n","df_games['GAME_ID']=df_games['GAME_ID'].astype(int)"]},{"cell_type":"markdown","metadata":{},"source":["5.Get the game date for every player"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for key in dic_group.keys():\n","    df_date=df_games[df_games['GAME_ID'].isin(dic_group[key]['GAME_ID'])].copy()\n","    \n","    df_date.drop_duplicates('GAME_ID',keep='first',inplace=True)\n","    df_date.set_index('GAME_ID',inplace=True)\n","    print(key)\n","    dic_group[key]['GAME_ID']=dic_group[key]['GAME_ID'].astype(int)\n","   \n","    for row in range(dic_group[key].shape[0]):\n","        if dic_group[key].loc[row,'GAME_ID'] in df_date.index:\n","            dic_group[key].loc[row,'GAME_DATE_EST']=df_date.loc[dic_group[key].loc[row,'GAME_ID'],'GAME_DATE_EST']\n","    dic_group[key].dropna(subset=['GAME_DATE_EST'],inplace=True)\n","    dic_group[key].set_index('GAME_DATE_EST',inplace=True)\n","    dic_group[key].sort_index(ascending=True,inplace=True)#reverse the sequence\n","   # dic_group1[key].index=np.arange(dic_group1[key].shape[0])\n","print(dic_group[group[0]][['GAME_ID']])\n","\n"]},{"cell_type":"markdown","metadata":{"id":"P008_3R08nms"},"source":["6.Plot time series"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":601},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1699404064150,"user":{"displayName":"Haoyang Ling","userId":"12767123704845142451"},"user_tz":300},"id":"s6I28HXS8nmv","outputId":"91388ec1-c05b-4805-b231-a68edb705228"},"outputs":[],"source":["internal=200\n","for key in dic_group.keys():\n","    y_pts=dic_group[key]['PTS']\n","    y_fgm=dic_group[key]['FGM']\n","    y_fg3m=dic_group[key]['FG3M']\n","    y_time=dic_group[key]['MIN']\n","    x_ticks=np.arange(dic_group[key].shape[0])\n","    num=int(dic_group[key].shape[0]/internal)\n","    new_xticks=np.arange(num)  \n","    new_xticks=[x*internal for x in new_xticks]\n","    new_xticks.append(dic_group[key].shape[0]-50)\n","    xlabels=[dic_group[key].index[x] for x in new_xticks]\n","    plt.subplots(figsize=(16, 6))\n","    plt.title(f'{key} PTS\\FGM\\FG3M\\MIN  trend')\n","    plt.ylabel('number')\n","    plt.xticks(new_xticks,xlabels,rotation=45,fontsize=8) \n","    plt.plot(y_pts,color='b',label='PTS')\n","    plt.plot(y_fgm,color='y',label='FGM')\n","    plt.plot(y_fg3m,color='g',label='FG3M')\n","    plt.plot(y_time,color='r',label='MIN')\n","    plt.legend()\n","    plt.show()\n","\n","\n","    "]},{"cell_type":"markdown","metadata":{"id":"apzd5mxs8nmv"},"source":["These stars show cyclical changes in playing time and the performance of major offensive and defensive indicators, even at the end of their careers, the relevant data did not appear to be significantly worse in one direction"]},{"cell_type":"markdown","metadata":{"id":"3B7Epx9T8nmw"},"source":["# 2. Stationarity Tests\n","\n","1.Calculate the rolling mean and standard deviation of the input time series."]},{"cell_type":"markdown","metadata":{"id":"EbVY__PT8nmw"},"source":["\n","\n","The size of the rolling window is governed by the argument `wd_size`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"furVP27G8nmw"},"outputs":[],"source":["# calculate the weighted moving average\n","\n","def calc_wma(ser, wd_size, weights=1):\n","    if isinstance(weights, int):\n","        weights = np.full(wd_size, weights, dtype=float)\n","\n","    wma = []\n","    for i in range(len(ser)):\n","        low, high = max(0, i - wd_size + 1), i + 1\n","        wma.append(np.average(ser.iloc[low: high], weights=weights[-(high - low):]))\n","    return np.array(wma)"]},{"cell_type":"markdown","metadata":{},"source":["calculate the rolling statistics,use PTS and BLK respectively"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mIgLB4gw8nmw"},"outputs":[],"source":["\n","wd_size = 7 # our window size, k\n","dic_group1_rolling_data={}\n","dic_group2_rolling_data={}\n","for key in dic_group.keys():\n","    first_mmt = calc_wma(dic_group[key]['PTS'], wd_size)\n","    second_mmt = calc_wma(dic_group[key]['PTS'] ** 2, wd_size)\n","    rolling_data=[]\n","    rolling_mean = first_mmt\n","    rolling_std = np.sqrt(second_mmt - first_mmt ** 2)\n","    rolling_data.append(rolling_mean)\n","    rolling_data.append(rolling_std)\n","    dic_group1_rolling_data[key]=rolling_data\n","print(dic_group1_rolling_data)\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["2.plot the time series and the rolling statistics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":622},"executionInfo":{"elapsed":1130,"status":"ok","timestamp":1699404065272,"user":{"displayName":"Haoyang Ling","userId":"12767123704845142451"},"user_tz":300},"id":"TGynR3QJ8nmx","outputId":"50828060-9f24-4b0b-a8a6-a8f82f9df1a2"},"outputs":[],"source":["\n","\n","for key in dic_group.keys():\n","    y_pts=dic_group[key]['PTS']\n","    y_mean=dic_group1_rolling_data[key][0]\n","    y_std=dic_group1_rolling_data[key][1]\n","    x_ticks=np.arange(dic_group[key].shape[0])\n","    num=int(dic_group[key].shape[0]/internal)\n","    new_xticks=np.arange(num)  \n","    new_xticks=[x*internal for x in new_xticks]\n","    new_xticks.append(dic_group[key].shape[0]-50)\n","    xlabels=[dic_group[key].index[x] for x in new_xticks]\n","    plt.subplots(figsize=(16, 6))\n","    plt.title(f\"{key} PTS trend \\n\" + f\"Rolling Stats with Window Size = {wd_size} \")\n","    plt.ylabel('number')\n","    plt.xticks(new_xticks,xlabels,rotation=45,fontsize=8) \n","    plt.plot(y_pts,color='b',label='Original')\n","    plt.plot(y_mean,color='r',label='mean')\n","    plt.plot(y_std,color='g',label='std')\n","    plt.legend()\n","    plt.show()\n","    \n"]},{"cell_type":"markdown","metadata":{},"source":["3.set a window size of 3 "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wd_size = 3 # our window size, k\n","dic_group1_rolling_data={}\n","dic_group2_rolling_data={}\n","for key in dic_group.keys():\n","    first_mmt = calc_wma(dic_group[key]['PTS'], wd_size)\n","    second_mmt = calc_wma(dic_group[key]['PTS'] ** 2, wd_size)\n","    rolling_data=[]\n","    rolling_mean = first_mmt\n","    rolling_std = np.sqrt(second_mmt - first_mmt ** 2)\n","    rolling_data.append(rolling_mean)\n","    rolling_data.append(rolling_std)\n","    dic_group1_rolling_data[key]=rolling_data\n","print(dic_group1_rolling_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for key in dic_group.keys():\n","    y_pts=dic_group[key]['PTS']\n","    y_mean=dic_group1_rolling_data[key][0]\n","    y_std=dic_group1_rolling_data[key][1]\n","    x_ticks=np.arange(dic_group[key].shape[0])\n","    num=int(dic_group[key].shape[0]/internal)\n","    new_xticks=np.arange(num)  \n","    new_xticks=[x*internal for x in new_xticks]\n","    new_xticks.append(dic_group[key].shape[0]-50)\n","    xlabels=[dic_group[key].index[x] for x in new_xticks]\n","    plt.subplots(figsize=(16, 6))\n","    plt.title(f\"{key} PTS trend \\n\" + f\"Rolling Stats with Window Size = {wd_size} \")\n","    plt.ylabel('number')\n","    plt.xticks(new_xticks,xlabels,rotation=45,fontsize=8) \n","    plt.plot(y_pts,color='b',label='Original')\n","    plt.plot(y_mean,color='r',label='mean')\n","    plt.plot(y_std,color='g',label='std')\n","    plt.legend()\n","    plt.show()\n","    \n"]},{"cell_type":"markdown","metadata":{},"source":["4.set a window size of 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wd_size = 10 # our window size, k\n","dic_group1_rolling_data={}\n","dic_group2_rolling_data={}\n","for key in dic_group.keys():\n","    first_mmt = calc_wma(dic_group[key]['PTS'], wd_size)\n","    second_mmt = calc_wma(dic_group[key]['PTS'] ** 2, wd_size)\n","    rolling_data=[]\n","    rolling_mean = first_mmt\n","    rolling_std = np.sqrt(second_mmt - first_mmt ** 2)\n","    rolling_data.append(rolling_mean)\n","    rolling_data.append(rolling_std)\n","    dic_group1_rolling_data[key]=rolling_data\n","print(dic_group1_rolling_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for key in dic_group.keys():\n","    y_pts=dic_group[key]['PTS']\n","    y_mean=dic_group1_rolling_data[key][0]\n","    y_std=dic_group1_rolling_data[key][1]\n","    x_ticks=np.arange(dic_group[key].shape[0])\n","    num=int(dic_group[key].shape[0]/internal)\n","    new_xticks=np.arange(num)  \n","    new_xticks=[x*internal for x in new_xticks]\n","    new_xticks.append(dic_group[key].shape[0]-50)\n","    xlabels=[dic_group[key].index[x] for x in new_xticks]\n","    plt.subplots(figsize=(16, 6))\n","    plt.title(f\"{key} PTS trend \\n\" + f\"Rolling Stats with Window Size = {wd_size} \")\n","    plt.ylabel('number')\n","    plt.xticks(new_xticks,xlabels,rotation=45,fontsize=8) \n","    plt.plot(y_pts,color='b',label='Original')\n","    plt.plot(y_mean,color='r',label='mean')\n","    plt.plot(y_std,color='g',label='std')\n","    plt.legend()\n","    plt.show()\n","    \n"]},{"cell_type":"markdown","metadata":{},"source":["# Conclusion\n","As can be seen from Window size 3, 7, and 10, the trend of the mean and the original values remains consistent,at the same time, std deviation is kept in a small floating range,so time series above is stationary.\n","Comparing Window size 3, 7, and 10, it should be that the smaller the window, the better the performance of window size 3, indicating that the window size should not be too large."]},{"cell_type":"markdown","metadata":{"id":"fWOfwueJ8nmx"},"source":["# 3. Seasonal patterns\n","\n","seasonal patterns analyse using PTS and BLK."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eb5IFKkv8nmx"},"outputs":[],"source":["for key in dic_group.keys():\n","    dic_group[key].dropna(subset=['PTS'],inplace=True)\n","    dic_group[key].reset_index(inplace=True)\n","    \n","    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_average=[]\n","for key in dic_group.keys():\n","    year_data=[]\n","    year_data_all=[]\n","    year_record=[]\n","    year1=''\n","    year2=''\n","    for row in range(dic_group[key].shape[0]-1):\n","        year1=dic_group[key].loc[row,'GAME_DATE_EST'].split('-')[0]\n","        year2=dic_group[key].loc[row+1,'GAME_DATE_EST'].split('-')[0]\n","        if year1==year2:\n","            year_data.append(dic_group[key].loc[row,'PTS'])\n","        else:\n","            year_record.append(year1)\n","            year_data.append(dic_group[key].loc[row,'PTS'])\n","            year_data_all.append(year_data.copy())\n","            year_data=[]\n","    year_data_all.append(year_data.copy())\n","    year_record.append(year1)\n","    print(key)\n","    plt.subplots(figsize=(20, 6))\n","    data_list=[]\n","    for index in range(len(year_data_all)):\n","        plt.plot(year_data_all[index],label=year_record[index]+' '+str(sum(year_data_all[index])))\n","        data_list.append(sum(year_data_all[index]))\n","    plt.title(f'{key} PTS every year')\n","    plt.legend()\n","    plt.show()\n","    \n","    plt.subplots(figsize=(20, 6))\n","    plt.title(f'{key} PTS trend every year')\n","    plt.plot(year_record,data_list)\n","    for index in range(len(year_record)):\n","        plt.text(index,data_list[index],data_list[index])\n","    plt.show()\n","    \n","    data_average.append(sum(data_list)/len(year_record))\n","plt.title(f'{list(dic_group.keys())[0]} VS {list(dic_group.keys())[1]} average annual PTS')\n","for index in range(len(dic_group.keys())):\n","    plt.bar(list(dic_group.keys())[index],data_average[index])\n","    plt.text(index,data_average[index],data_average[index])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_average=[]\n","for key in dic_group.keys():\n","    year_data=[]\n","    year_data_all=[]\n","    year_record=[]\n","    year1=''\n","    year2=''\n","    for row in range(dic_group[key].shape[0]-1):\n","        year1=dic_group[key].loc[row,'GAME_DATE_EST'].split('-')[0]\n","        year2=dic_group[key].loc[row+1,'GAME_DATE_EST'].split('-')[0]\n","        if year1==year2:\n","            year_data.append(dic_group[key].loc[row,'FGM'])\n","        else:\n","            year_record.append(year1)\n","            year_data.append(dic_group[key].loc[row,'FGM'])\n","            year_data_all.append(year_data.copy())\n","            year_data=[]\n","    year_data_all.append(year_data.copy())\n","    year_record.append(year1)\n","    print(key)\n","    plt.subplots(figsize=(20, 6))\n","    data_list=[]\n","    for index in range(len(year_data_all)):\n","        plt.plot(year_data_all[index],label=year_record[index]+' average '+str(round(sum(year_data_all[index])/len(year_data_all[index]),2)))\n","        data_list.append(round(sum(year_data_all[index])/len(year_data_all[index]),2))\n","    plt.title(f'{key} FGM every year')\n","    plt.legend()\n","    plt.show()\n","    \n","    plt.subplots(figsize=(20, 6))\n","    plt.title(f'{key} FGM trend every year')\n","    plt.plot(year_record,data_list)\n","    for index in range(len(year_record)):\n","        plt.text(index,data_list[index],data_list[index])\n","    plt.show()\n","    \n","    data_average.append(round(sum(data_list)/len(year_record),2))\n","plt.title(f'{list(dic_group.keys())[0]} VS {list(dic_group.keys())[1]} average annual FGM')\n","for index in range(len(dic_group.keys())):\n","    plt.bar(list(dic_group.keys())[index],data_average[index])\n","    plt.text(index,data_average[index],data_average[index])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_average=[]\n","for key in dic_group.keys():\n","    year_data=[]\n","    year_data_all=[]\n","    year_record=[]\n","    year1=''\n","    year2=''\n","    for row in range(dic_group[key].shape[0]-1):\n","        year1=dic_group[key].loc[row,'GAME_DATE_EST'].split('-')[0]\n","        year2=dic_group[key].loc[row+1,'GAME_DATE_EST'].split('-')[0]\n","        if year1==year2:\n","            year_data.append(dic_group[key].loc[row,'FG3M'])\n","        else:\n","            year_record.append(year1)\n","            year_data.append(dic_group[key].loc[row,'FG3M'])\n","            year_data_all.append(year_data.copy())\n","            year_data=[]\n","    year_data_all.append(year_data.copy())\n","    year_record.append(year1)\n","    print(key)\n","    plt.subplots(figsize=(20, 6))\n","    data_list=[]\n","    for index in range(len(year_data_all)):\n","        plt.plot(year_data_all[index],label=year_record[index]+' average '+str(round(sum(year_data_all[index])/len(year_data_all[index]),2)))\n","        data_list.append(round(sum(year_data_all[index])/len(year_data_all[index]),2))\n","    plt.title(f'{key} FG3M every year')\n","    plt.legend()\n","    plt.show()\n","    \n","    plt.subplots(figsize=(20, 6))\n","    plt.title(f'{key} FG3M trend every year')\n","    plt.plot(year_record,data_list)\n","    for index in range(len(year_record)):\n","        plt.text(index,data_list[index],data_list[index])\n","    plt.show()\n","    \n","    data_average.append(round(sum(data_list)/len(year_record),2))\n","plt.title(f'{list(dic_group.keys())[0]} VS {list(dic_group.keys())[1]} average annual FG3M')\n","for index in range(len(dic_group.keys())):\n","    plt.bar(list(dic_group.keys())[index],data_average[index])\n","    plt.text(index,data_average[index],data_average[index])\n","plt.show()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.7.8rc1 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"f6c3fe0f35ac205adeee3d33d4d27f45ea8735944f6bcc7cc4d72c9672a115a8"}}},"nbformat":4,"nbformat_minor":0}
